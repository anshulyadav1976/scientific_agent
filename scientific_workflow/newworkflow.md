# Portia Scientific Research Workflow Plan

## 1. Introduction

This document outlines a scientific research workflow designed for the Portia SDK. It prioritizes data analysis, integrates specialized scientific search and citation tools, and leverages a powerful LLM (like Gemini 1.5 Pro) for planning, synthesis, code generation, and report writing. This workflow adapts concepts from the previous CAMEL agent but is structured specifically for scientific tasks.

## 2. Core Principles

*   **Data-First:** If input data is provided, analyze it early to inform subsequent research.
*   **Scientific Rigor:** Prioritize information from scientific databases; use web search for broader context.
*   **Reproducibility:** Include code execution for calculations/visualizations and manage citations.
*   **LLM Orchestration:** Utilize a capable LLM for complex reasoning, generation, and planning tasks, coordinating specialized tools.

## 3. Required Tools

This workflow requires the following Portia tools:

*   **`llm_tool`:** Configured for Gemini 1.5 Pro (or similar capable model).
*   **`data_ingestion_tool`:** Handles loading, cleaning (numeric conversion), and type detection (tabular, unstructured) of input files. Outputs summary, detected type, and cleaned file path.
*   **`analysis_tool`:** Performs detailed statistical analysis (correlations, outliers, descriptive stats) on tabular data. Input: file path. Output: Structured analysis results.
*   **`scientific_search_tool` (New/Enhanced):** Queries scientific databases (e.g., PubMed, ArXiv, Semantic Scholar) and general web search. Input: list of search queries. Output: Structured list of findings (`source_type`, `title`, `snippet`, `url_or_doi`).
*   **`code_execution_tool` (New):** Executes Python code (generated by `llm_tool`) in a sandboxed environment. Input: Python code string. Output: Dictionary containing `stdout`, `stderr`, and `output_files` (list of paths to generated files like plots).
*   **`citation_tool` (New):** Formats citations based on a list of source identifiers (URLs/DOIs). Input: list of source strings. Output: Formatted citation list/string.

## 4. Proposed Portia Plan Steps

1.  **Step 1: Ingest & Initial Assessment (`data_ingestion_tool` & `llm_tool`)**
    *   **Action (Tool):** `data_ingestion_tool` processes the input file provided by the user.
    *   **Output:** `$ingestion_output` (`{detected_type: '...', summary: '...', file_path: '...'}`)
    *   **Action (LLM):** `llm_tool` analyzes the `user_prompt` and `$ingestion_output` to create an initial plan.
    *   **Prompt (LLM):** "Based on user prompt '{user_prompt}' and ingested data summary '$ingestion_output.summary' (type: '$ingestion_output.detected_type'), define the main research goal. Determine if analysis of the provided data is required ('`analysis_required`: true/false'). Outline key research questions and list initial keywords/topics for literature/web search. Output JSON: `{'goal': '...', 'analysis_required': true/false, 'research_questions': [...], 'search_topics': [...]}`"
    *   **Output:** `$initial_plan` (`{goal: '...', analysis_required: ..., research_questions: [...], search_topics: [...]}`)

2.  **Step 2: Data Analysis (Conditional) (`analysis_tool`)**
    *   **Condition:** `$initial_plan.analysis_required == true`
    *   **Input:** `file_path` argument set to `$ingestion_output.file_path`.
    *   **Action:** Execute `analysis_tool`.
    *   **Output:** `$analysis_results` (Structured JSON/Dict)

3.  **Step 3: Generate Search Queries (`llm_tool`)**
    *   **Inputs:** `$initial_plan.search_topics`, `$analysis_results` (if Step 2 ran).
    *   **Prompt:** "Generate specific, effective search queries based on the research topics (`$initial_plan.search_topics`) and any relevant findings from the data analysis (`$analysis_results`). Create separate queries suitable for scientific databases (PubMed, ArXiv) and general web search. Prefix queries appropriately (e.g., 'pubmed:', 'web:'). Output a list of query strings."
    *   **Output:** `$search_queries` (List of strings)

4.  **Step 4: Execute Scientific & Web Search (`scientific_search_tool`)**
    *   **Input:** `queries` argument set to `$search_queries`.
    *   **Action:** Execute `scientific_search_tool`, iterating through the generated queries. Tool should handle routing to appropriate databases/web search based on prefixes or other logic.
    *   **Output:** `$search_findings` (List of structured results: `{'source_type': 'pubmed/web/arxiv', 'title': '...', 'snippet': '...', 'url_or_doi': '...'}`)

5.  **Step 5: Synthesize Findings & Identify Sources (`llm_tool`)**
    *   **Inputs:** `$search_findings`, `$analysis_results` (if available), `$initial_plan.research_questions`.
    *   **Prompt:** "Synthesize information from search results (`$search_findings`) and data analysis (`$analysis_results`). Address the `$initial_plan.research_questions`. Prioritize evidence from scientific sources (PubMed, ArXiv) for core claims, using web sources for context. Extract key findings, conflicting information, and gaps. List all source URLs/DOIs used for the synthesis. Output JSON: `{'synthesis_summary': '...', 'source_identifiers': [...]}`"
    *   **Output:** `$synthesis_output` (`{synthesis_summary: '...', source_identifiers: [...]}`)

6.  **Step 6: Generate Code (`llm_tool`)**
    *   **Inputs:** `$synthesis_output.synthesis_summary`, `$analysis_results` (if available).
    *   **Prompt:** "Based on the synthesis (`$synthesis_output.synthesis_summary`) and analysis (`$analysis_results`), generate Python code for ONE relevant task: visualize a key finding (e.g., plot correlation, distribution using matplotlib/seaborn), run a simple simulation (numpy/scipy), or perform a specific calculation. Code should save outputs (e.g., `/plots/figure1.png`) or print results. Output *only* the raw Python code block."
    *   **Output:** `$python_code` (String)

7.  **Step 7: Execute Code (`code_execution_tool`)**
    *   **Input:** `code` argument set to `$python_code`.
    *   **Action:** Execute `code_execution_tool`.
    *   **Output:** `$code_results` (`{'stdout': '...', 'stderr': '...', 'output_files': [...]}`)

8.  **Step 8: Format Citations (`citation_tool`)**
    *   **Input:** `source_identifiers` argument set to `$synthesis_output.source_identifiers`.
    *   **Action:** Execute `citation_tool` (specify desired format like APA via args if tool supports it).
    *   **Output:** `$formatted_citations` (String or List of strings)

9.  **Step 9: Create Final Report (`llm_tool`)**
    *   **Inputs:** `$synthesis_output.synthesis_summary`, `$code_results`, `$formatted_citations`, `$initial_plan.goal`, `$analysis_results` (if available).
    *   **Prompt:** "Generate a final scientific report in Markdown. Sections: Introduction (based on `$initial_plan.goal`), Key Findings (from `$synthesis_output.synthesis_summary`), Data Analysis Summary (if `$analysis_results` provided), Code Execution Results (incorporating `$code_results.stdout` and reference files in `$code_results.output_files`), Discussion, Conclusion, References (using `$formatted_citations`)."
    *   **Output:** `$final_report` (Markdown string)

10. **Step 10: Evaluate Report (`llm_tool`)** (Optional)
    *   **Inputs:** `$final_report`, `$initial_plan.goal`.
    *   **Prompt:** "Evaluate the `$final_report` for scientific rigor, clarity, completeness regarding the `$initial_plan.goal`, and proper inclusion of analysis, code results, and citations. Provide a brief evaluation summary."
    *   **Output:** `$report_evaluation`

## 5. LLM Choice (Gemini 1.5 Pro)

Using Gemini 1.5 Pro via the `llm_tool` offers significant advantages:

*   **Large Context Window:** Can handle extensive initial content, detailed prompts, and large amounts of search results for synthesis without losing context.
*   **Strong Reasoning:** Capable of complex instruction following needed for planning, synthesis, code generation, report generation, and evaluation steps.
*   **Potential Multimodality:** While not used in the current plan, its ability to handle images/video could be leveraged in future scientific workflows (e.g., analyzing chart images).
*   **Cost-Effectiveness:** Generally offers competitive pricing for its capabilities.

We need to ensure the `llm_tool` in our setup is correctly configured to interface with the Gemini API.

## 6. Next Steps

1.  **Implement New Tools:** Create Python classes for `ScientificSearchTool`, `CodeExecutionTool`, `CitationTool`.
2.  **Refine Existing Tools:** Ensure `DataIngestionTool`, `AnalysisTool` align.
3.  **Tool Registration:** Register all tools.
4.  **Craft Detailed Plan Prompt:** Translate Section 4 into the `plan_prompt` in `research_agent.py`.
5.  **Configure Tools & LLM.**
6.  **Update Agent Logic.**
7.  **Frontend Adaptation:** Handle display of potential plot files, etc.
8.  **Test and Iterate.**
